---
layout: post
title: "A deep-learning model of prescient ideas demonstrates that they emerge from the periphery "
author: Paul Vicinanza, Amir Goldberg, Sameer Srivastava
date: 2022-12-06
categories: [research, social]
tags: [innovation, large-language-model]
---

[https://doi.org/10.1093/pnasnexus/pgac275](https://doi.org/10.1093/pnasnexus/pgac275)

https://osf.io/preprints/socarxiv/j24pw/ 

> Where do prescient ideas—those that initially challenge conventional assumptions but later achieve widespread acceptance—come from? Although their outcomes in the form of technical innovation are readily observed, the underlying ideas that eventually change the world are often obscured. 
>
> Here we develop a novel method that uses deep learning to unearth the markers of prescient ideas from the language used by individuals and groups. 
>
> Our language-based measure identifies prescient actors and documents that prevailing methods would fail to detect. Applying our model to corpora spanning the disparate worlds of politics, law, and business, we demonstrate that it reliably detects prescient ideas in each domain. Moreover, counter to many prevailing intuitions, **prescient ideas emanate from each domain's periphery rather than its core**. 
>
> These findings suggest that **the propensity to generate far-sighted ideas may be as much a property of contexts as of individuals.**

