---
layout: post
title: "It takes a Flaywheel to fly: Kickstarting and keeping the A/B testing momentum"
author: Aleksander Fabijan et al.
date: 2020-12-28
categories: [data, teamwork]
tags: [best-practice, strategy]
---
[https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/it-takes-a-flywheel-to-fly-kickstarting-and-keeping-the-a-b-testing-momentum/](https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/it-takes-a-flywheel-to-fly-kickstarting-and-keeping-the-a-b-testing-momentum/)

> In this article, we present the A/B Testing Flywheel â€“ a tool for implementing and growing a successful A/B testing program. Our flywheel focuses on navigating the value-investment cycle which supports and motivates the continued funding required to scale up an A/B testing program.
>
> We developed the A/B Testing Flywheel based on our experience and learnings from introducing and embedding A/B testing in over two dozen product teams at Microsoft (where Aleksander & Benjamin work), Outreach (Pavel), and Booking.com (Lukas).
>
> **Running the first A/B test.** The analysis of our data shows that the growth of A/B testing program often starts with a single team trying out A/B testing in one specific scenario, such as the signup flow on a website, or ranking optimization in a shopping app. **In this initial stage, A/B tests need to be chosen wisely.** Why? Well, initial success may quickly propel the A/B testing program forward, while failure may stop the program in its tracks before it had a chance to get going**.**
>
> We found the following factors to be important when selecting initial A/B tests: **High value potential, Simple to execute, Easy to measure.**

![img](https://www.microsoft.com/en-us/research/uploads/prod/2020/12/ABTestingFlywheel.png)

