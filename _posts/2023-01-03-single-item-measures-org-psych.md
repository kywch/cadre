---
layout: post
title: "Normalizing the use of single-item measures: Validation of the single-item compendium for organizational psychology"
author: Russell Matthews, Laura Pineault, Yeong-Hyun Hong
date: 2022-04-14
categories: [research, cognitive]
tags: assessment
---

[https://link.springer.com/article/10.1007/s10869-022-09813-3](https://link.springer.com/article/10.1007/s10869-022-09813-3)

> The application of single-item measures has the potential to help applied researchers address conceptual, methodological, and empirical challenges. Based on a large-scale evidence-based approach, we empirically examined the degree to which various constructs in the organizational sciences can be reliably and validly assessed with a single item. 
>
> In study [1](https://link.springer.com/article/10.1007/s10869-022-09813-3#Sec3), **across 91 selected constructs, 71.4% of the single-item measures demonstrated *strong* if not *very strong* definitional correspondence (as a measure of content validity)**. 
>
> In study [2](https://link.springer.com/article/10.1007/s10869-022-09813-3#Sec9), based on a heterogeneous sample of working adults, we demonstrate that the majority of single-item measures examined demonstrated little to no comprehension or usability concerns. Study [3](https://link.springer.com/article/10.1007/s10869-022-09813-3#Sec15) provides evidence for the reliability of the proposed single-item measures based on test–retest reliabilities across the three temporal conditions (1 day, 2 weeks, 1 month). In study [4](https://link.springer.com/article/10.1007/s10869-022-09813-3#Sec20), we examined issues of construct and criterion validity using a multi-trait, multi-method approach. Collectively, 75 of the 91 focal measures demonstrated *very good* or *extensive* validity, evidencing moderate to high content validity, no usability concerns, moderate to high test–retest reliability, and extensive criterion validity. Finally, in study [5](https://link.springer.com/article/10.1007/s10869-022-09813-3#Sec28), we empirically examined the argument that only conceptually narrow constructs can be reliably and validly assessed with single-item measures. Results suggest that there is no relationship between subject matter expert evaluations of construct breadth and reliability and validity evidence collected across the first four studies. 
>
> Beyond providing an off-the-shelf compendium of validated single-item measures, we abstract our validation steps providing a roadmap to replicate and build upon. Limitations and future directions are discussed.
