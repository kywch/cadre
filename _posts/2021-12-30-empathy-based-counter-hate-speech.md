---
layout: post
title: "Empathy-based counterspeech can reduce racist hate speech in a social media field experiment"
author: Dominik Hangartner, et al.
date: 2021-12-14
categories: [research, social]
tags: choicelogy
---

[https://www.pnas.org/content/118/50/e2116310118](https://www.pnas.org/content/118/50/e2116310118)

> Despite heightened awareness of the detrimental impact of hate speech on social media platforms on affected communities and public discourse, there is little consensus on approaches to mitigate it. While content moderation—either by governments or social media companies—can curb online hostility, such policies may suppress valuable as well as illicit speech and might disperse rather than reduce hate speech. 
>
> As an alternative strategy, an increasing number of international and nongovernmental organizations (I/NGOs) are employing counterspeech to confront and reduce online hate speech. Despite their growing popularity, there is scant experimental evidence on the effectiveness and design of counterspeech strategies (in the public domain). 
>
> Modeling our interventions on current I/NGO practice, we randomly assign English-speaking Twitter users who have sent messages containing xenophobic (or racist) hate speech to one of three counterspeech strategies—empathy, warning of consequences, and humor—or a control group. 
>
> Our intention-to-treat analysis of 1,350 Twitter users shows that **empathy-based counterspeech messages can increase the retrospective deletion of xenophobic hate speech by 0.2 SD and reduce the prospective creation of xenophobic hate speech over a 4-wk follow-up period by 0.1 SD.** We find, however, no consistent effects for strategies using humor or warning of consequences. 
>
> Together, these results advance our understanding of the central role of empathy in reducing exclusionary behavior and inform the design of future counterspeech interventions.

![img](https://www.pnas.org/content/pnas/118/50/e2116310118/F1.large.jpg?width=800&height=600&carousel=1)

> We randomly assigned the sampled Twitter user to one of three treatment arms (with 20% probability each) or the control group (40% probability). We focus on the following three treatments: 
>
> * empathy [blue box], where the message is designed to elicit empathy, for example, “For African Americans, it really hurts to see people use language like this”; 
> * warning of consequences [red box], where the message is designed to warn the sender about potential social consequences of their tweet, for example, “Hey, remember that your friends and family can see this tweet too”; and 
> * humor [green box], with a humorous picture (meme) of an animal, engaging in an obstructing behavior, with captions stating, for example, “It’s time to stop tweeting” or “Please stop tweeting.”
