---
layout: post
title: "The AI research job market shit show (and my experience)"
author: Nathan Lambert
date: 2023-10-11
categories: [venture, ml/ai/nlp]
tags: career
---

[https://www.interconnects.ai/p/ai-research-job-market](https://www.interconnects.ai/p/ai-research-job-market)

> Structurally, the places where open research and science are the priorities is exceedingly rare. Even if someone joins as an academically minded research scientist, realities will always pull people into the business needs (especially at startups).

> With the most surprising being getting visibility for your work is harder than doing good work. Love or hate the media strategy of startups like HuggingFace, they know how to help themselves grow in the public opinion, which matters. 

> Lightweight interview lessons
> The interviews here were very light, which is why I didn’t outline the timeline and scope like in my first job search post. More research chats, some coding interviews, lots of trying to figure out what the right fit is. If you’re looking for a job in LLMs, most of the questions will be about what different internal components do. I would recommend you know:
> * Exact details of how attention works at an implementation level. You can look at nanoGPT or many other sources.
> * Basics of multi-GPU training, estimating VRAM usage, hyperparameters to make the model footprint shrink (e.g. quantization).
> * Regularization tools like batch norm, dropout, weight decay, etc.

> Other than the technical side, always have a company-specific story of what you would work on with them. If you say the same thing to everyone, you’ll get much less traction (unless you’re very famous). Also, I found many companies looked at GitHub repos and HuggingFace artifacts listed on my CV, which may make for easier things to talk about than messy research projects.